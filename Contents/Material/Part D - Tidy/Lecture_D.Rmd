---
title: "Functions, tidyverse, SQLite"
author: "Javier Garcia-Bernardo (partly based on material by Gerko Vink)"
date: "Introduction to R and RStudio"
knit: (function(inputFile, encoding){
  rmarkdown::render(inputFile, output_format = "all") })
output: 
  ioslides_presentation:
    logo: logo.png
    smaller: true
    widescreen: true
    transition: 0
  pdf_document: default

---

## Recap:

#### Last week
- Intro to R/Rstudio: Data types and structures
- Subsetting structures
- Choice statements and for-loops
- Reproducibility (renv)
- Best practices (e.g., naming conventions)
- Reading and writing files in several formats

#### Today
- Functions
- Inferential statistics: A 5-min primer of linear regression
- Principles of tidy data and short comparison of base R and the tidyverse
- Data wrangling with the tidyverse
- Speeding up queries in large datasets



# Writing your own functions

## What are functions?

Functions are reusable pieces of code that 

1. take some standard input (e.g. a vector of numbers)
2. do some computation  (e.g. calculate the mean)
3. return some standard output (e.g. one number with the mean)

We have been using a lot of functions: code of the form `something()` is usually a function. 

```{r}
mean(1:6)
```

## Our own function

We can make our own functions as follows:

```{r}
squared <- function(x){
  x_square <- x * x
  return(x_square) 
}

squared(4)
```

`x`, the input, is called the (formal) *argument* of the function. `x_square` is called the *return value*.

## Our own function

If there is no `return()`, the last line is automatically returned, so we can also just write:


```{r}
square <- function(x){
  x * x
}

square(-2)
```

I do not recommend this, please always specify what you return unless you have a one-line function.


## Anonymous/Lambda expressions

```{r}
df <- data.frame("V1" = rnorm(5),
                 "V2" = rnorm(5, mean = 5, sd = 2), 
                 "V3" = rnorm(5, mean = 6, sd = 1))

head(df)
```

```{python, eval=FALSE, python.reticulate=FALSE}
#Python
df.apply(lambda x: np.percentile(x, .42))
```


```{r}
#R
sapply(df, {function(x) quantile(x, .42)})
```



## Default options in functions {.build}
* Default options for some arguments are provided in many functions. 
* They allow us to provide additional (optional) arguments

```{r}
is_contained <- function(str_1, str_2, print_input = TRUE){
  if (print_input){
    cat("Testing if", str_1, "contained in", str_2, "\n")
  }
  return(str_1 %in% str_2)
}
```


```{r, collapse=TRUE,eval=FALSE}
is_contained("R", "rstudio")
```
```{r, collapse=TRUE}
is_contained("R", "rstudio")
is_contained("R", "rstudio", print_input = TRUE)
is_contained("R", "rstudio", print_input = FALSE)
```

## Create documentation of functions

```{python, eval=FALSE, python.reticulate=FALSE, collapse=TRUE}
##Python
def square(x):
  """
  Squares a number

  Parameters:
  x (float): Number (or vector)

  Returns:
  float: Squared numbers
  """
  return(x**2)
```


```{r, collapse=TRUE}
##R more info at https://r-pkgs.org/man.html

#' Squares a number
#' 
#' @param x A number.
#' @returns A numeric vector.
#' @examples
#' square(3)
square <- function(x){
  return(x * x)
}
```





## Troubleshooting
* Your first self-written for-loop, or function, will probably not work.

* Don't panic! Just go line-by-line, keeping track of what is currently inside each variable. 
* Stackoverflow and LLMs are your friends.


# Scoping rules in `R` 

## Global environemnt (workspace)
  
When you write the name of a variable, R needs to find the value.

In the interactive computation (outside of functions, e.g., your console), this happens in the following order:

- First, search the global environment (i.e., your workspace) 
- If it cannot be found, search each of the loaded packages


```{r}
search()
```
The order of packages is important.



## Scoping rules in `R`: Functions

Inside a function, this happens in the following order:

- First, search within the function.
- If it cannot be found, search in the global environment (i.e., your workspace) 
- If it cannot be found, search each of the loaded packages


```{r, collapse=TRUE}
y <- 3
test_t <- function() {
  print(y)
}
test_t()
```


```{r, collapse=TRUE}
y <- 3
test_t <- function() {
  y <- 2
  print(y)
}
test_t()
```

## Scoping rules in `R`: Functions

What happens inside a function, stays within a function (unless you specify it differently)


```{r}
y <- 3
test_t <- function() {
  y <- 2
  print(y)
}
test_t()
y
```

## Scoping rules in `R`: Packages

Packages are neatly contained/isolated, so they are not affected by your code. They do so through namespaces: 

- Namespaces allow the package developer to hide functions and data.
- Objects in the global environment that match objects in the function's namespace are ignored when running functions from packages (prevent clashes)
- Functions are executed within the namespace of the package and have access to the global environment
- They provide a way to refer to an object, with the double colon `::`

```{r}
dplyr::n_distinct(c(1,2,3,4,2))
```

## Scoping rules in `R`: Packages (good practices)
- Pass to the function (using arguments) ***everything*** that the function needs to use (i.e. don't define something outside the function that is being used for the function)

BAD
```{r, eval=FALSE}

shifted_mean <- function(numbers) {
   return(mean(numbers) + shift_by)
}

shift_by <- 3
shifted_mean(c(1,2,3))
```

GOOD
```{r, eval=FALSE}
shifted_mean <- function(numbers, shift_by) {
   return(mean(numbers) + shift_by)
}

shift_by <- 3
shifted_mean(c(1,2,3), shift_by)
```



# Modeling

## Linear regression (model)

<img src="img/1mQN0yjE3oWr6GBzY0953pw.png" width="70%"/>   

Linear regression. Source: R. Kukuh (medium)
<!-- ![Linear regression. Source: R. Kukuh (medium)](img/1mQN0yjE3oWr6GBzY0953pw.png){width=70%} -->

## Linear regression (visual interpretation)

<img src="img/17tcfpzsXbrxROhVCB8BkBA.png" width="70%"/>   

Linear regression. Source: R. Kukuh (medium)
<!-- ![Linear regression. Source: R. Kukuh (medium)](img/17tcfpzsXbrxROhVCB8BkBA.png){width=100%} -->

## Linear regression (fitting)

<img src="img/1jJU6IrM4CsnGcOG1JIErxg.png" width="70%"/>   

Linear regression. Source: R. Kukuh (medium)
<!-- ![Linear regression. Source: R. Kukuh (medium)](img/1jJU6IrM4CsnGcOG1JIErxg.png){width=100%} -->



## Modeling in `R`
To model objects based on other objects, we use `~` (tilde)

For example, to model the relationship between body mass index (bmi) and weight, we would type
```{r eval=FALSE}
bmi ~ weight
```
The `~` is used to separate the dependent variable (left side) from the independent variables (right side).

For functions within the formula we use `I()`. For example, to model body mass index (BMI) on its deterministic function of weight and height, we would type
```{r eval=FALSE}
bmi ~ I(weight / height^2)
```



## We can then plug the formula into a model. {.build}


Let's use the boys dataset.
```{r echo=FALSE, message=FALSE, warning=FALSE}
# Reading the file in the background
boys <- readr::read_delim("../common_datasets/dataset_boys.csv",delim=",")
```

```{r, collapse = TRUE}
lm(bmi ~ wgt, data = boys)
```

```{r, collapse = TRUE}
lm(bmi ~ I(wgt / (hgt / 100)^2), data = boys)
```

## Why we really need `I()`
```{r,collapse=TRUE}
lm(bmi ~ wgt + wgt^2, data = boys)

lm(bmi ~ wgt + I(wgt^2), data = boys)
```

## More efficient
It is better to store the output from the function in an object. The convention for regression models is an object called `fit`. 
```{r}
fit <- lm(bmi ~ I(wgt / (hgt / 100)^2), data = boys)
```
The object `fit` contains a lot more than just the regression weights. To inspect what is inside you can use `attributes()`
```{r}
attributes(fit)
```

## Finding the coefficients

```{r}
summary(fit)
```



## Classes in R {.smaller}
```{r}
class(fit)
```

Classes are used in object-oriented programming. It defines a set of properties and methods that are common to all objects of one type. For example, no matter what model you fit, you'll always need some common attributes.


In `R`, objects are the instances of a class (i.e., all objects in R have a class).


When you apply a generic function to an object (e.g. class = "lm"), R first tries to find a function of the class of the object.


When a generic function function (e.g. `plot()`) is applied to an object with class attribute `"lm"`, the system searches for a function called `plot.lm()` and, if it finds it, applies it to the object. 

If `R` cannot find `plot.lm()` it then uses the default function (e.g. `plot()`)---if it exists. 

## Classes example: plotting without class
```{r, dev.args = list(bg = 'transparent')}
plot(bmi ~ wgt, data = boys)
```

## Classes example: plotting with class
```{r, dev.args = list(bg = 'transparent')}
plot(lm(bmi ~ wgt, data = boys), which = 1)
```

## Classes example: plotting with class
```{r, dev.args = list(bg = 'transparent')}
plot(lm(bmi ~ wgt, data = boys), which = 2)
```

## Classes example: plotting with class
```{r, dev.args = list(bg = 'transparent')}
plot(lm(bmi ~ wgt, data = boys), which = 3)
```

## Classes example: plotting with class
```{r, dev.args = list(bg = 'transparent')}
plot(lm(bmi ~ wgt, data = boys), which = 4)
```

## Classes example: plotting with class
```{r, dev.args = list(bg = 'transparent')}
plot(lm(bmi ~ wgt, data = boys), which = 5)
```

## Classes example: plotting with class
```{r, dev.args = list(bg = 'transparent')}
plot(lm(bmi ~ wgt, data = boys), which = 6)
```




# Reading and writing files in several formats

## Reading and Writing


Reading files
```{r, eval = FALSE, echo = TRUE}
#install.packages(c("readr","readxl","haven","foreign","Hmisc","feather"),
#repos = "http://cran.us.r-project.org")

readr::read_delim("here_path.csv", delim = ",") #CSV
readr::read_rds("here_path.Rds") #RDS (R format)
readxl::read_excel("here_path.xlsx") #Excel
haven::read_dta("here_path.dta") #Stata
haven::read_sav("here_path.sav") #SPSS
feather::read_feather("tmp/here_path.feather") #feather
```

Writing to files
```{r, eval = FALSE, echo = TRUE}
#install.packages(c("writexl"),
#    repos = "http://cran.us.r-project.org")

## Writing
readr::write_delim(virginia,"tmp/here_path.csv", delim = ",") #CSV
readr::write_rds(virginia,"tmp/here_path.Rds") #RDS (R format)
writexl::write_xlsx(virginia,"tmp/here_path.xlsx") #Excel
haven::write_dta(virginia,"tmp/here_path.dta") #Stata
haven::write_sav(virginia,"tmp/here_path.sav") #SPSS
feather::write_feather(virginia, "tmp/here_path.feather") #feather
```

## Reading and writing
- CSV: Easy to use, share, open in excel or a text editor.
- RDS: binary format, only for `R`. Your factors (categorical variables) will stay as factors. Small size and decent read time.
- feather: binary format, efficient for large data files and to share.
![https://bookdown.org/csgillespie/efficientR/input-output.html](img/5-2-1.png){width=50%}



# Principles of tidy data

## Library

```{r}
library(tidyverse)
```


## Tidy  data {.build}

Simple but extremely useful idea:

1.  Each variable has its own column.
2.  Each observation has its own row.
3.  Each value has its own cell.

<img src="img/tidy-1.png" width="70%"/>   

Source: R for data science

Original paper of [Tidy Data](http://www.jstatsoft.org/v59/i10/paper)

<!-- ![Source: R for data science](img/tidy-1.png){width=70%} -->





## Tidy vs non-tidy data {.build}

There are three variables in this data set. What are they?


```{r, echo = FALSE}
tibble::tribble(
  ~"", ~`2010`, ~`2015`,
  #--|--|----
  "Male", 0, 5,
  "Female", 1, 4
)
```



```{r, echo = FALSE}
tibble::tribble(
  ~year, ~gender, ~count,
  #--|--|----
  2010, "Female", 1,
  2010, "Female", 0,
  2015, "Male", 4,
  2015, "Male", 5,
)
```


## What are the variables in the following dataset


```{r,message = FALSE}
#Death rates per 1000 in Virginia in 1940.
virginia <- readr::read_csv("../common_datasets/virginia.txt")
names(virginia) <- c("Age","Rural Male","Rural Female","Urban Male","Urban Female")
virginia
```



## Advantages of tidy data

1. Consistent way of storing data = reuse of tools/code
2. Facilitate manipulation, visualization and modelling
  * Combining tables (e.g., merging two tables by year)
  * Plotting: you'll typically want to show how one variable depends on another (y ~ x)
  * Statistical models (y ~ x + year)
3. Performance: R is fast applying functions to columns (vectorized)


## e.g. merging dataset

<img src="img/datasets.png" width="100%"/>   

<!-- ![Merging](img/datasets.png){width=100%} -->


## How to fix datasets: Melting (pivot_longer) {.build}

```{r, collapse=TRUE}
df <- tibble::tribble(
  ~"gender", ~"2010", ~"2015",
  #--|--|----
  "Male", 0, 5,
  "Female", 1, 4
)
df
```
```{r, collapse=TRUE}
tidyr::pivot_longer(df, cols = c("2010","2015"), names_to = "year", values_to = "count")
```



## How to fix datasets: Pivot_wider {.build}
```{r, collapse=TRUE}
df <- tibble::tribble(
  ~"gender", ~"variable", ~"value",
  #--|--|----
  "Male", "happiness", 5,
  "Male", "count", 5,
)
df
```

```{r, collapse=TRUE}
tidyr::pivot_wider(df, id_cols = c("gender"), names_from = "variable", values_from = "value")
```




# Tidy vs base R

## Reading the data 

```{r, message=FALSE}
data <- readr::read_csv("../common_datasets/dataset_boys.csv", col_select = c("age","wgt","bmi","reg") )
data
```


## Subsetting (columns)
:::: {style="display: flex;"}

::: {.column width="50%"}

base `R`
```{r}
data[, c("age","bmi")]
```
:::

::: {.column width="50%"}

tidyverse
```{r}
dplyr::select(data, age, bmi)
```

:::

::::


## Subsetting (rows)
:::: {style="display: flex;"}

::: {.column width="50%"}

base `R`
```{r}
data[data$age > 20, ]
```
:::

::: {.column width="50%"}

tidyverse
```{r}
dplyr::filter(data, age > 20)
```

:::

::::

## Drop missing values

:::: {style="display: flex;"}

::: {.column width="50%"}

base `R`
```{r}
nans <- rowSums(is.na(data[, c("bmi","reg")]))
data[!nans,]

```


:::

::: {.column width="50%"}

tidyverse
```{r}
tidyr::drop_na(data, 
               bmi,  reg)
```

:::

::::


## Sort (by age (descending) and bmi (ascending)


:::: {style="display: flex;"}



::: {.column width="50%"}

base `R`
```{r}
data[order(rev(data$age), data$bmi), ]
```
:::

::: {.column width="50%"}

tidyverse
```{r}
dplyr::arrange(data, desc(age), bmi) 
```

:::

::::


## Creating new column in a new data frame

:::: {style="display: flex;"}

::: {.column width="50%"}

base `R`
```{r}
new_data <- data
new_data$age_sqrt <- sqrt(new_data$age)
new_data
```
:::

::: {.column width="50%"}

tidyverse
```{r}
new_data <- dplyr::mutate(data,
                          age_srt = sqrt(age))
new_data
```

:::

::::


## Applying a function by columns (map is more consistent)

:::: {style="display: flex;"}

::: {.column width="50%"}

base `R`
```{r}
sum_nans <- function(x) {sum(is.na(x))}
apply(data, MARGIN = 2, 
      FUN = sum_nans)
```

```{r}
lapply(data, sum_nans)
```

:::

::: {.column width="50%"}


tidyverse
```{r}
sum_nans <- function(x) {sum(is.na(x))}
#Returns a vector of integer (map_xxx)
purrr::map_int(data, sum_nans)
```

```{r}
purrr::map(data, sum_nans)
```

:::

::::


## Merge

:::: {style="display: flex;"}

::: {.column width="50%"}

base `R`
```{r}
#Decent syntax (sorts desc.)
system.time(
  merg <- merge(data, data, by = "reg")
  )
merg[, c("reg", "age.x","age.y")]
```
:::

::: {.column width="50%"}

tidyverse
```{r}
#Similar syntax, but much faster! (sorts ascendingly)
system.time(
  merg <- dplyr::inner_join(data, data, by = "reg")
  )
select(merg, reg,age.x,age.y)
```

:::

::::

## Main data structure

:::: {style="display: flex;"}

::: {.column width="50%"}

base `R`: data.frame

- Prints okay
```{r, collapse=TRUE}
data.frame(x=1:2, y=2:1)
# 
# 
```
- Recycle rules are error-prone
```{r, collapse=TRUE}
data.frame(x=1:4, y=c(1,2))

```
:::

::: {.column width="50%"}

tidyverse: [tibble](https://r4ds.had.co.nz/tibbles.html)

- Prints nicely
```{r, collapse=TRUE}
tibble(x=1:2, y=2:1)
```

- Does not recycle arguments of length > 1
```{r, error=TRUE}
tibble(x=1:4, y=c(1,2))
```

:::

::::


## Main structure

:::: {style="display: flex;"}

::: {.column width="50%"}

base `R`: data.frame

- Tries to read your mind (error-prone)

```{r}
d <- data.frame(variable=1:4)
d$var
```


- Subsetting a data.frame returns often a vector
```{r, error=TRUE}
#
d <- data.frame(x=1:4, y=1)
d[, "x"] #d["x"] returns a data.frame
```


:::

::: {.column width="50%"}

tidyverse: tibble

- Does not try to read your mind
```{r, error=TRUE}
d <- tibble(variable=1:4)
d$var
```


- Subsetting a tibble returns a tibble
```{r, error=TRUE}
d <- tibble(x=1:4, y=1)
d[, "x"]  # d[["x"]] or d$x returns a vector
```
- Renaming columns
```{r}
rename(d, new_var_x = x)
```

:::

::::


## Main structure

:::: {style="display: flex;"}

::: {.column width="50%"}

base `R`: data.frame

- Renaming is annoying and does not scale well 

```{r}
d_new <- d
names(d_new)[names(d_new) == 'x'] <- 'new_var_x'
```

- Works with all packages. Can be converted to a tibble easily.

```{r}
as_tibble(d_new)
```
:::

::: {.column width="50%"}

tidyverse: tibble


- Renaming columns
```{r}
d_new <- dplyr::rename(d, new_var_x = x)
#
```

- Does not work with some old packages. Can be converted to a data.frame easily.

```{r}
as.data.frame(d_new)
```
:::

::::


## Summarize by group

:::: {style="display: flex;"}

::: {.column width="50%"}


base `R`
- Drops the entire row if there is one missing value
```{r}
aggregate(cbind(age, wgt, bmi) ~ reg, 
          data = data, 
          FUN = mean)
```
:::

::: {.column width="50%"}


tidyverse
- Does not drop the entire row if there is one missing value
```{r}
data |> 
  dplyr::group_by(reg) |> 
  dplyr::summarise_all(mean, na.rm = TRUE)
```

:::

::::

## Pipes: A short intro

Step by step
```{r, eval=FALSE}
grouped_data <- dplyr::group_by(data, reg) 
summarized_data <- dplyr::summarise_all(grouped_data, mean, na.rm = TRUE)
```

The pipe takes the output of the command *before* `|>` and passes it as input for the command *after* `|>`.

It reduces the overhead (no need to save intermediate output), organizes the code into coherent blocks, and increases readability.
```{r, eval=FALSE}
summarized_data <- data |> 
  dplyr::group_by(reg) |>  
  dplyr::summarise_all(mean, na.rm = TRUE)
```
- Base R has since version 4.1 its own pipe (`|>`), before the pipe  was provided by the `magrittr` package and it looked like: `%>%`.

## Data wrangling summary
- [Cheatsheet data tidying with tidyr](https://posit.co/wp-content/uploads/2022/10/data-transformation-1.pdf)
- [Cheatsheet data transformation with dplyr](https://posit.co/wp-content/uploads/2022/10/tidyr.pdf)


- Main functions `dplyr`:
  - `mutate`: add column
  - `select`: select columns
  - `filter`: filter rows
  - `distinct`: remove duplicates
  - `arrange`: sort rows
  - `group_by` + `summarize` / `summarize_all`: apply function to groups
  
- Main functions `tidyr`:
  - `drop_na`: remove rows with missing values
  - `fill`: fill missing values with a value
  - `pivot_wider`(data, names_from = "name",
values_from = "value")
  - `pivot_longer`(data, cols, names_to = "name",
values_to = "value", values_drop_na = FALSE)
  
  

## Why tidyverse

- Perfect to work with tidy data
- Easier syntax
- More intuitive
- Less error prone
- It has its own ecosystem of complementary packages
- All/most functions in the tidyverse can be used in pipes
- Huge community of fanatics


# Practical


# Bigger data

## IMDB data

Their data on movies and actors is freely available at https://developer.imdb.com/non-commercial-datasets/


```{r eval=FALSE}
#Download data
download.file("https://datasets.imdbws.com/title.basics.tsv.gz", "db/title_basics.tsv.gz", mode = "wb")
```


```{r warning = FALSE}
data_imdb <- readr::read_delim("db/title_basics.tsv.gz", delim = "\t", na = "\\N", show_col_types = FALSE)

#10,375,265 rows, 9 columns
data_imdb
```


## Time to read data


Time to read data:
```{r warning=FALSE}
system.time(
  data_imdb <- readr::read_delim("db/title_basics.tsv.gz", delim = "\t", na = "\\N", show_col_types = FALSE)
)
```

Time to query:
```{r}
system.time(
  results <- data_imdb |> 
    dplyr::group_by(startYear) |> 
    dplyr::summarize(number_movies = n()) |> 
    arrange(number_movies)
)
```

## Speed up using a database (SQL)

Use database instead of a file

```{r}
#install.packages("DBI")
#install.packages("RSQLite")
#install.packages("dbplyr")
library(DBI) #Database access
library(RSQLite) #SQLite
library(dbplyr) #query without using SQL
```

## Dump the data to a SQLite.database

SQLite is a lightweight, self-contained, and serverless relational database management system (RDBMS). It's contained as a file in your computer. It's designed for simplicity and efficiency.

```{r}
# Connect to SQLite database
db <- DBI::dbConnect(RSQLite::SQLite(), "db/imdb.db") #try :memory: instead of a file
# Write the data frame to the SQLite database using dbplyr
DBI::dbWriteTable(db, "title_basics", data_imdb, overwrite = TRUE)
DBI::dbWriteTable(db, "title_basics_no_index", data_imdb, overwrite = TRUE)
# Create an index on startYear
DBI::dbExecute(db, "CREATE INDEX idx_startYear ON title_basics(startYear);")
# Close the database connection
DBI::dbDisconnect(db)
```

## Some operations on the table

Reading the tables
```{r}
db <- DBI::dbConnect(RSQLite::SQLite(), "db/imdb.db") #try :memory: instead of a file
DBI::dbListTables(db)
```

Reading the fields of a table
```{r}
DBI::dbListFields(db, "title_basics")
```


## Running query
```{r}
# Connect to the table
con <- DBI::dbConnect(RSQLite::SQLite(), "db/imdb.db")
data_imdb_db <- dplyr::tbl(con, "title_basics")

# Create the query (note that it's exactly the same code)
data_imdb_query <- data_imdb_db |> 
                   dplyr::group_by(startYear) |> 
                   dplyr::summarize(number_movies = n()) |> 
                   dplyr::arrange(desc(number_movies))

# Show query
data_imdb_query |> dplyr::show_query()

# Disconnect from server (done at the end)
DBI::dbDisconnect(con)
```
## Performance (without index)

```{r}
# Run the query
system.time({
  # Connect to database
  con <- DBI::dbConnect(RSQLite::SQLite(), "db/imdb.db")
  data_imdb_db <- dplyr::tbl(con, "title_basics_no_index")
  
  # Create the query (note that it's exactly the same code)
  data_imdb_query <- data_imdb_db |> 
                     dplyr::group_by(startYear) |> 
                     dplyr::summarize(number_movies = n()) |> 
                     dplyr::arrange(desc(number_movies))
  
  # Collect the data (query is run here)
  results <- data_imdb_query |> dplyr::collect()
})

# Disconnect
DBI::dbDisconnect(con)
```

## Performance (with index)

```{r}
# Run the query
system.time({
  # Connect to database
  con <- DBI::dbConnect(RSQLite::SQLite(), "db/imdb.db")
  data_imdb_db <- dplyr::tbl(con, "title_basics")
  
  # Create the query (note that it's exactly the same code)
  data_imdb_query <- data_imdb_db |> 
                     dplyr::group_by(startYear) |> 
                     dplyr::summarize(number_movies = n()) |> 
                     dplyr::arrange(desc(number_movies))
  
  # Collect the data (query is run here)
  results <- data_imdb_query |> dplyr::collect()
})

# Disconnect
DBI::dbDisconnect(con)
```

## Results


```{r}
head(results, 10)
```


## Results (visually)

```{r compact=TRUE}
library(ggplot2)

ggplot(data = results, aes(y=number_movies, x=startYear)) + 
  geom_line(color = "cornflowerblue", linewidth = 1) +
  theme_minimal() +
  labs(x = "Year", y = "Number of movies") +
  lims(y = c(0, 5E5))
```

## SQLite summary

We sped the query from ~12 seconds (~11 to read the file + ~0.40 for the query) to ~0.38 seconds. And there are many other perks of using SQLite (e..g data integrity).

However: `dbplyr` is not great at creating efficient queries from tidyverse. 




